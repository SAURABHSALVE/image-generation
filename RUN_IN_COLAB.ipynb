{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¨ AI Image Studio - Ultra Fast Colab Deploy\n",
    "\n",
    "## âš¡ Optimized for Speed - Just run this ONE cell! ğŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš€ ULTRA-FAST ONE-CLICK DEPLOY - RUN THIS CELL!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ğŸ“¦ Installing dependencies (2-3 minutes)...\")\n",
    "import subprocess\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"streamlit\", \"torch\", \"diffusers\", \"transformers\", \"accelerate\", \"pillow\", \"opencv-python-headless\", \"pyngrok\"], \n",
    "               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "print(\"âœ… Dependencies installed!\\n\")\n",
    "\n",
    "# Upload file\n",
    "from google.colab import files\n",
    "print(\"ğŸ“¤ Upload your app file:\")\n",
    "print(\"   - app_colab.py (recommended - fastest)\")\n",
    "print(\"   - app_enhanced.py (LCM only - fast)\")\n",
    "print(\"   - thisartdoesnotexist.py (simple)\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "app_file = list(uploaded.keys())[0]\n",
    "print(f\"\\nâœ… Uploaded: {app_file}\\n\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "device = \"GPU\" if torch.cuda.is_available() else \"CPU\"\n",
    "print(f\"ğŸ–¥ï¸  Device: {device}\")\n",
    "if device == \"CPU\":\n",
    "    print(\"âš ï¸  Running on CPU. Enable GPU for 10x speed: Runtime â†’ Change runtime type â†’ GPU\\n\")\n",
    "else:\n",
    "    print(\"âœ… GPU detected! Generation will be super fast!\\n\")\n",
    "\n",
    "# Run app\n",
    "import threading, time, sys, os\n",
    "from pyngrok import ngrok\n",
    "\n",
    "os.environ['STREAMLIT_SERVER_HEADLESS'] = 'true'\n",
    "\n",
    "def run_app():\n",
    "    subprocess.run([\n",
    "        sys.executable, \"-m\", \"streamlit\", \"run\", app_file,\n",
    "        \"--server.port\", \"8501\",\n",
    "        \"--server.headless\", \"true\",\n",
    "        \"--logger.level\", \"error\",\n",
    "        \"--server.enableCORS\", \"false\",\n",
    "        \"--server.enableXsrfProtection\", \"false\"\n",
    "    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "threading.Thread(target=run_app, daemon=True).start()\n",
    "\n",
    "print(\"â³ Starting app (20 seconds)...\")\n",
    "time.sleep(20)\n",
    "\n",
    "url = ngrok.connect(8501)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ YOUR APP IS LIVE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸŒ Public URL: {url}\")\n",
    "print(f\"\\nğŸ“± Share this URL with anyone!\")\n",
    "print(f\"\\nğŸ’¡ Tips:\")\n",
    "print(f\"   â€¢ Keep this cell running to keep app alive\")\n",
    "print(f\"   â€¢ LCM model only needs 4-8 steps (super fast!)\")\n",
    "print(f\"   â€¢ Use 512x512 or smaller for fastest results\")\n",
    "if device == \"CPU\":\n",
    "    print(f\"   â€¢ Enable GPU for 10x speed: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "print(f\"   â€¢ Stop cell (â¹ï¸) to shut down app\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Keep running\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nğŸ›‘ App stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ That's It!\n",
    "\n",
    "Your app is now running and accessible via the public URL above.\n",
    "\n",
    "### âš¡ Speed Optimization Tips:\n",
    "\n",
    "#### 1. Enable GPU (10x Faster!) ğŸš€\n",
    "- Click **Runtime** â†’ **Change runtime type**\n",
    "- Select **GPU** (T4 or better)\n",
    "- Click **Save**\n",
    "- Run the cell above again\n",
    "\n",
    "#### 2. Use Optimal Settings in App:\n",
    "- **Steps**: 4-8 (LCM only needs this!)\n",
    "- **Size**: 512x512 or smaller\n",
    "- **Guidance**: 1.0-1.5 (LCM optimal range)\n",
    "\n",
    "#### 3. Generation Speed Comparison:\n",
    "- **CPU + 512x512 + 6 steps**: ~20-40 seconds\n",
    "- **GPU + 512x512 + 6 steps**: ~3-8 seconds âš¡âš¡âš¡\n",
    "- **GPU + 256x256 + 4 steps**: ~1-3 seconds âš¡âš¡âš¡âš¡âš¡\n",
    "\n",
    "### ğŸ“Š Model Info:\n",
    "\n",
    "Both apps now use **LCM (Latent Consistency Model)**:\n",
    "- âœ… 10x faster than Stable Diffusion v1.5\n",
    "- âœ… Only needs 4-8 steps (vs 20-50 for SD)\n",
    "- âœ… Same quality as SD v1.5\n",
    "- âœ… Works great on CPU and GPU\n",
    "\n",
    "### ğŸ› Troubleshooting:\n",
    "\n",
    "| Problem | Solution |\n",
    "|---------|----------|\n",
    "| App won't start | Restart runtime and try again |\n",
    "| URL not working | Wait 30 seconds, then refresh |\n",
    "| Out of memory | Enable GPU or use 256x256 size |\n",
    "| Slow generation | Enable GPU + use 4-6 steps |\n",
    "| Connection timeout | Keep this tab open |\n",
    "\n",
    "### ğŸ’¡ Pro Tips:\n",
    "\n",
    "1. **Fastest Setup**: GPU + 256x256 + 4 steps = 1-3 seconds!\n",
    "2. **Best Quality**: GPU + 512x512 + 8 steps = 5-10 seconds\n",
    "3. **CPU Mode**: 384x384 + 6 steps = 15-25 seconds\n",
    "4. **Batch Generation**: Generate 1 image at a time for faster feedback\n",
    "5. **Keep Tab Open**: Colab needs browser tab active\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Files You Can Upload:\n",
    "\n",
    "### 1. **app_colab.py** â­ (Recommended)\n",
    "- Optimized for Colab\n",
    "- Clean output, no warnings\n",
    "- Fast LCM model\n",
    "- Simple interface\n",
    "- **Best for**: Quick testing and demos\n",
    "\n",
    "### 2. **app_enhanced.py** (Feature-Rich)\n",
    "- LCM model only (fast!)\n",
    "- Text-to-image\n",
    "- Image-to-image\n",
    "- Random art generator\n",
    "- Artistic filters\n",
    "- Post-processing\n",
    "- **Best for**: Full-featured app\n",
    "\n",
    "### 3. **thisartdoesnotexist.py** (Simple)\n",
    "- One-click random art\n",
    "- Minimal interface\n",
    "- Fast generation\n",
    "- **Best for**: Simple art generation\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¨ Enjoy Creating!\n",
    "\n",
    "Your AI Image Studio is now live and ready to generate amazing images in seconds!\n",
    "\n",
    "### Expected Performance:\n",
    "- **With GPU**: 3-8 seconds per image âš¡\n",
    "- **Without GPU**: 20-40 seconds per image\n",
    "\n",
    "### Colab Limits:\n",
    "- **Free tier**: 12 hours max per session\n",
    "- **GPU quota**: Limited hours per week\n",
    "- **Keep browser open**: Required for session\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Next Steps:\n",
    "\n",
    "1. âœ… App is running (check URL above)\n",
    "2. ğŸ¨ Open URL in new tab\n",
    "3. âš¡ Enable GPU if not already\n",
    "4. ğŸ–¼ï¸ Start generating images!\n",
    "5. ğŸ“± Share URL with friends\n",
    "\n",
    "Happy creating! ğŸ¨âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
