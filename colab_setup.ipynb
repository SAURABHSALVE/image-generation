{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé® AI Image Studio - Google Colab (Optimized)\n",
                "\n",
                "**Fast LCM Model Only** - Generates images in 10-30 seconds!\n",
                "\n",
                "## What This Does:\n",
                "- Creates a streamlined AI image generator\n",
                "- Uses LCM (Latent Consistency Model) - 10x faster!\n",
                "- Works on both CPU and GPU\n",
                "- Gives you a public URL to share\n",
                "\n",
                "## Just Run All Cells! ‚¨áÔ∏è"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Dependencies (2-3 minutes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üì¶ Installing dependencies...\")\n",
                "!pip install -q streamlit torch diffusers transformers pillow pyngrok\n",
                "print(\"‚úÖ Installation complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Upload Your Files\n",
                "\n",
                "Upload these files from your local machine:\n",
                "- `app_enhanced.py` OR `thisartdoesnotexist.py`\n",
                "- `.env` (optional, for HuggingFace token)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Upload your Python file\n",
                "print(\"üì§ Upload your app file (app_enhanced.py or thisartdoesnotexist.py)\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Get the uploaded filename\n",
                "app_file = list(uploaded.keys())[0]\n",
                "print(f\"‚úÖ Uploaded: {app_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Create .env File (Optional)\n",
                "\n",
                "If you want to use HuggingFace API for faster generation:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Set your HuggingFace token\n",
                "# Get token from: https://huggingface.co/settings/tokens\n",
                "\n",
                "HF_TOKEN = \"\"  # Paste your token here (optional)\n",
                "\n",
                "if HF_TOKEN:\n",
                "    with open('.env', 'w') as f:\n",
                "        f.write(f\"HF_TOKEN={HF_TOKEN}\\n\")\n",
                "    print(\"‚úÖ .env file created with HF_TOKEN\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No HF_TOKEN set - will use local generation only\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Install Localtunnel for Public URL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install localtunnel for public URL\n",
                "!npm install -g localtunnel"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Run Streamlit App with Public URL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import threading\n",
                "import time\n",
                "from IPython.display import display, HTML\n",
                "\n",
                "# Start Streamlit in background\n",
                "def run_streamlit():\n",
                "    subprocess.run([\"streamlit\", \"run\", app_file, \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n",
                "\n",
                "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
                "thread.start()\n",
                "\n",
                "print(\"‚è≥ Starting Streamlit app...\")\n",
                "time.sleep(10)\n",
                "\n",
                "# Start localtunnel\n",
                "print(\"üåê Creating public URL...\")\n",
                "!lt --port 8501 &\n",
                "\n",
                "time.sleep(5)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ APP IS RUNNING!\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nüì± Your app is accessible at:\")\n",
                "print(\"   https://[random-subdomain].loca.lt\")\n",
                "print(\"\\n‚ö†Ô∏è Look for the URL in the output above\")\n",
                "print(\"\\nüí° Tips:\")\n",
                "print(\"   - First time: Click 'Click to Continue' on the localtunnel page\")\n",
                "print(\"   - Keep this cell running to keep the app alive\")\n",
                "print(\"   - Stop the cell to shut down the app\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Alternative: Use Ngrok (More Reliable)\n",
                "\n",
                "If localtunnel doesn't work, use ngrok:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install pyngrok\n",
                "!pip install -q pyngrok\n",
                "\n",
                "from pyngrok import ngrok\n",
                "import subprocess\n",
                "import threading\n",
                "import time\n",
                "\n",
                "# Optional: Set your ngrok auth token (get from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
                "NGROK_TOKEN = \"\"  # Paste your token here (optional but recommended)\n",
                "\n",
                "if NGROK_TOKEN:\n",
                "    ngrok.set_auth_token(NGROK_TOKEN)\n",
                "\n",
                "# Start Streamlit in background\n",
                "def run_streamlit():\n",
                "    subprocess.run([\"streamlit\", \"run\", app_file, \"--server.port\", \"8501\", \"--server.headless\", \"true\"])\n",
                "\n",
                "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
                "thread.start()\n",
                "\n",
                "print(\"‚è≥ Starting Streamlit app...\")\n",
                "time.sleep(10)\n",
                "\n",
                "# Create ngrok tunnel\n",
                "public_url = ngrok.connect(8501)\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"‚úÖ APP IS RUNNING!\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nüì± Your app is accessible at:\")\n",
                "print(f\"   {public_url}\")\n",
                "print(\"\\nüí° Tips:\")\n",
                "print(\"   - Share this URL with anyone\")\n",
                "print(\"   - Keep this cell running to keep the app alive\")\n",
                "print(\"   - Stop the cell to shut down the app\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ You're Done!\n",
                "\n",
                "Your app is now running and accessible via the public URL.\n",
                "\n",
                "### What to expect:\n",
                "- **app_enhanced.py**: Full-featured AI Image Studio with multiple models\n",
                "- **thisartdoesnotexist.py**: Simple random art generator\n",
                "\n",
                "### Performance on Colab:\n",
                "- **With GPU**: 5-15 seconds per image\n",
                "- **Without GPU (CPU)**: 30-90 seconds per image\n",
                "- **LCM model**: 10-30 seconds even on CPU!\n",
                "\n",
                "### To use GPU (faster):\n",
                "1. Go to Runtime ‚Üí Change runtime type\n",
                "2. Select GPU (T4)\n",
                "3. Restart and run all cells again"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}